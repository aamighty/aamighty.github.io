---
layout: post
title: Categorizing Reddit Posts Based on their Titles
---

### Objective:
The goal of this project is to use natural language processing to determine the subreddit based on the title of a post. The data includes all posts made to tech related subreddits in December 2016.

### Data Exploration
I took a look at the distribution of the number of posts by subreddit and noticed that the dataset is disproportionally _techsupport_ (we'll deal with that later). 
![_config.yml]({{ site.baseurl }}/images/reddit-count.png)

I grouped subreddits that have similar titles (ex: _pythoncoding_ and _Python_) and kept the nine subreddits with most observations. 
![_config.yml]({{ site.baseurl }}/images/consolidated-count.png)

### Data Cleaning/Preprosessing
The method of natural language processing used to clean the dataset was **term frequency inverse document frequency (tfidf)**. Tfidf looks at the frequency of a certain word in each title with respect to the frequency of that word in the entire dataset. This technique reweights terms to strengthen those that are highly specific to a particular document, while suppressing terms that are common to most documents. Because the titles are only a few words long, we want to focus on words that are unique and therefore informative to our model.

### Determine the Baseline
Before we can evaluate whether our classifier's accuracy is good or bad, we need to know the **baseline accuracy**. The baseline accuracy is the proportion of the majority class. It tells us the how often out model would be correct if it predicts that every observation belongs to the majority class. 

For this dataset the majority class is _techsupport_ and the baseline is 0.429. 

### Modeling
The data set was split into a training set and a test set. The training set is used to fit the model and then test set is used to determine how well our model performs on unseen data. The tfidf preprocessed titles were fed into a random forest classifier model. The reults of the model are as follows: 

|:---|---|
|Training Score | 0.940907921811|
|Test Score | 0.693643127529|

The score of both the training and testing sets are larger than the baseline so we know that the model is doing more than just predicting all classes to be _techsupport_. However, there is a relatively large difference between the two scores so let's dig a bit deeper to see how the model is really doing. To do this, we'll look at the **recall score** in the classification report.
![_config.yml]({{ site.baseurl }}/images/reddit_sub_codes.png)

![_config.yml]({{ site.baseurl }}/images/reddit_class_report.png)

Looking at the classification report, we 
